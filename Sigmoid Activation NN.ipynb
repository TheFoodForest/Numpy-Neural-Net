{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sci "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('titanic_train_kaggle.csv')\n",
    "data.head()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 714 entries, 0 to 890\n",
      "Data columns (total 4 columns):\n",
      "Survived    714 non-null int64\n",
      "Sex         714 non-null int32\n",
      "Age         714 non-null float64\n",
      "Fare        714 non-null float64\n",
      "dtypes: float64(2), int32(1), int64(1)\n",
      "memory usage: 25.1 KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pd.set_option('display.max_rows', 714)\n",
    "data = pd.DataFrame(data[[\n",
    "    'Survived',\n",
    "    'Sex',\n",
    "    'Age',\n",
    "    'Fare'\n",
    "]])\n",
    "data = data.dropna()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "age = data['Age'].values.reshape(-1,1)\n",
    "data['Age'] = scaler.fit_transform(age)\n",
    "\n",
    "fare = data['Fare'].values.reshape(-1,1)\n",
    "data['Fare'] = scaler.fit_transform(fare)\n",
    "\n",
    "data['Sex'] = data['Sex'].map({'female':0,'male':1}).astype(int)\n",
    "\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return (1/(1 + np.exp(-x)))\n",
    "\n",
    "              \n",
    "def sig_der(x):\n",
    "    return (sigmoid(x) * (1 - sigmoid(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights Before Train\n",
      "[[-0.80002935]\n",
      " [-0.19538899]\n",
      " [-0.3610783 ]]\n",
      "Weights After Train\n",
      "[[-2.32319388]\n",
      " [-0.17152863]\n",
      " [ 0.69777696]]\n",
      "[1.05011163]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "learning_rate = .01\n",
    "\n",
    "inputs = data.loc[:,['Sex','Age','Fare']].values\n",
    "train_outputs = data.loc[:,'Survived'].values\n",
    "weights = np.random.randn(3,1)*np.sqrt(2/(3))\n",
    "print('Weights Before Train')\n",
    "print(weights)\n",
    "\n",
    "B = .05\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    input_layer = inputs\n",
    "    X = np.dot(input_layer,weights) + B\n",
    "    outputs = sigmoid(X)\n",
    "\n",
    "    train_outputs = train_outputs.reshape(-1,1)\n",
    "\n",
    "    error = outputs - train_outputs\n",
    "    \n",
    "    der = sig_der(outputs)\n",
    "    z_delta = error * der\n",
    "    \n",
    "#     adjust = np.dot(input_layer.T, sig_der(input_layer, weights, B) * error)\n",
    "    \n",
    "    weights -= learning_rate * np.dot(input_layer.T,z_delta)\n",
    "    for num in z_delta:\n",
    "        B -= learning_rate * num\n",
    "\n",
    "print('Weights After Train')\n",
    "print(weights)\n",
    "print(B)\n",
    "out_r = []\n",
    "for i in outputs:\n",
    "    if i >= 0.5:\n",
    "        out_r.append(1)\n",
    "    else:\n",
    "        out_r.append(0)\n",
    "# print(list(zip(out_r,train_outputs)))\n",
    "\n",
    "# print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.      0.      0.     ...  0.      1.      1.    ]\n",
      " [22.     38.     26.     ... 19.     26.     32.    ]\n",
      " [ 7.25   71.2833  7.925  ... 30.     30.      7.75  ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Weights After Train\n",
    "[[-2.33628522]\n",
    " [-0.17116952]\n",
    " [ 0.69766165]]\n",
    "[1.05987224]\n",
    "\n",
    "\n",
    "print(input_layer.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25.17038551]\n",
      " [-8.98270461]\n",
      " [-8.07417637]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(adjust)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1= Survived 0= Did Not Survive\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82       424\n",
      "           1       0.74      0.69      0.72       290\n",
      "\n",
      "    accuracy                           0.78       714\n",
      "   macro avg       0.77      0.76      0.77       714\n",
      "weighted avg       0.78      0.78      0.78       714\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def ModelScore(y_true, y_pred,output):\n",
    "    print('1= Survived', '0= Did Not Survive')\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    fpr, tpr, thresholds = roc_curve(y_true,output)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='Model (area = %.2f)'% roc_auc)\n",
    "    plt.plot([0,1],[0,1], 'r--')\n",
    "    plt.xlim([0.0,1.0])\n",
    "    plt.ylim([0.0,1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Reciever Operating Characteristic')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    \n",
    "ModelScore(train_outputs,out_r,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b94aad2ab44f9ebc8bfb2bfa1fb1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=135.0, description='ix', max=360.0, step=15.0), FloatSlider(value=20.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interactive\n",
    "import ipywidgets as widgets\n",
    "\n",
    "x = data['Sex'].values\n",
    "y = data['Fare'].values\n",
    "graph_weight = []\n",
    "B = 0.5\n",
    "for i in range(100):\n",
    "    graph_weight.append(np.random.randint(-5,5,size=3)/np.random.randint(1,5,size=3))\n",
    "\n",
    "\n",
    "errors = []\n",
    "for i in range(100):\n",
    "    pred = np.array(sigmoid(np.dot(input_layer,graph_weight[i]))).ravel()\n",
    "\n",
    "    error = np.mean((pred - train_outputs)**2)\n",
    "    errors.append(error)\n",
    "    \n",
    "    \n",
    "errors = np.array(errors) \n",
    "\n",
    "x = [graph_weight[i][0] for i in range(100)]\n",
    "y = [graph_weight[i][1] for i in range(100)]\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "import matplotlib.cm as cm\n",
    "def plot(ix,iy):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.plot_trisurf(x,y,errors,cmap=cm.magma)\n",
    "\n",
    "    ax.view_init(iy,ix)\n",
    "    ax.set_title('Loss Function for Single Layer Perceptron NN')\n",
    "    ax.set_xlabel('Weight1 (multiplied by Sex)')\n",
    "    ax.set_ylabel('Weight2 (multiplied by Age)')\n",
    "    ax.set_zlabel('Loss')\n",
    "\n",
    "inter_plot = interactive(plot,ix=widgets.FloatSlider(min=0,max=360,step=15,value=135),iy=widgets.FloatSlider(min=0,max=360,step=15,value=20))\n",
    "inter_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Building NN Class with hidden relu activation layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    @staticmethod\n",
    "    def activation(z):\n",
    "        z[z<0] = 0\n",
    "        return z\n",
    "    @staticmethod\n",
    "    def prime(z):\n",
    "        z[z<0] = 0\n",
    "        z[z>0] = 1\n",
    "        return z\n",
    "    \n",
    "    \n",
    "class Sigmoid:\n",
    "    @staticmethod\n",
    "    def activation(z):\n",
    "        return 1 / (1+ np.exp(-z))\n",
    "    @staticmethod\n",
    "    def prime(z):\n",
    "        return Sigmoid.activation(z) * (1 - Sigmoid.activation(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, dimensions, activations):\n",
    "        #dimensions param: tuple of dimensions for NN, (input, hidden layer, output)\n",
    "        #activations param: tuple of activation fuctions\n",
    "        self.n_layers = len(dimensions)\n",
    "        self.loss = None\n",
    "        self.learning_rate = None\n",
    "        \n",
    "        self.w = {}\n",
    "        self.b = {}\n",
    "        self.activations = {}\n",
    "        for i in range(len(dimensions) - 1):\n",
    "            self.w[i+1] = np.random.randn(dimensions[i],dimensions[i+1]) / np.sqrt(dimensions[i])\n",
    "            self.b[i+1] = 2 * np.random.random_sample(dimensions[i+1]) + 1\n",
    "            self.activations[i+2] = activations[i]\n",
    "            \n",
    "\n",
    "    def _feed_forward(self, x):\n",
    "        #param x: array of input data vectors( array of arrays )\n",
    "        \n",
    "        #pass data forward through NN\n",
    "        #z has keys 2 and 3 for the weightged sums at each neuron\n",
    "        ### so z[2] is (n_rows_training, n_neurons in layer2) shape\n",
    "        ### each row in z[2] has four columns, each row represents a row of training data being passed\n",
    "        ### through NN and each column is the sum of that training row at a given nueron (x1w1 +x2w2... +xnwn +b)\n",
    "        ### the weights will be differnet for each x going into each neuron\n",
    "        \n",
    "        # z = W1X1 + W2X2 ... + WnXn + Bias \n",
    "        z = {}\n",
    "        \n",
    "        #outputs or activations of each layer\n",
    "        #input layer 1 just outputs the inputs\n",
    "        # input layer 2 (for RElU then Sigmoid network) outputs used in next iteration of z\n",
    "        \n",
    "        # a = f(z)\n",
    "        a = {1 : x}\n",
    "        \n",
    "        for i in range(1, self.n_layers):\n",
    "            #fill z[i+1] with dot product of weights[i'th layer] and outputs (a) of i'th layer\n",
    "            z[i+1] = np.dot(a[i], self.w[i]) + self.b[i]\n",
    "            #fill outputs (a[i+1]) by applying activation fuction[i+1] (only layer 2 and 3 have activation)  to \n",
    "            #to the just calculated z[i+1] dot prod of weght * x\n",
    "            a[i+1] = self.activations[i+1].activation(z[i+1])\n",
    "         \n",
    "        #dictionaries with keys for corresponding layer\n",
    "        return z, a\n",
    "    \n",
    "    def predict(self, x):\n",
    "        #x param: array containing x input array\n",
    "        \n",
    "        _ , a = self._feed_forward(x)\n",
    "        \n",
    "        #returns last layer's output\n",
    "        #this is the models prediction \n",
    "        #here is is through sigmoid function so between 0-1 for proba survive\n",
    "        return a[self.n_layers]\n",
    "        \n",
    "    def _update_w_b(self, index, dw, delta):\n",
    "        #index param: index of layer \n",
    "        #dw param: array of partial derivatives for weights \n",
    "        #delta param: delta error (combined partial dervatives for chain rule for partial der with respect to weights)\n",
    "        \n",
    "        #subtract learning rate times derivative of cost fuction with respect to each weight at each layer \n",
    "        #from each corresponding weight to move weights towards more accurate (less loss) values\n",
    "        # Bias partial derivative is slightly differnt than weights and needs one less chain-rule to calculate\n",
    "        \n",
    "        self.w[index] -= self.learning_rate * dw \n",
    "        self.b[index] -= self.learning_rate * np.mean(delta, 0)\n",
    "        \n",
    "    def _back_prop(self, z, a , y_true):\n",
    "        #z param: dictionary w(x) +b\n",
    "        # a param: dict f(z)\n",
    "        #loss will be called in the 'fit' method, using MSE here\n",
    "        #delta method returns partial derivative of loss func w respect to essentially error\n",
    "        #times the derivative of optimization function at given layer\n",
    "       \n",
    "        \n",
    "        delta = self.loss.delta(y_true, a[self.n_layers])\n",
    "        \n",
    "        #matrix multiply delta by the given layers transposed inputs and thats the three chains for partial \n",
    "        #derivative of loss function\n",
    "        #doing all in matrix multiplication is much faster than using for/while loops and essentially calculates\n",
    "        #all partial derivatives at once\n",
    "        \n",
    "        dw = np.dot(a[self.n_layers - 1].T, delta)\n",
    "        \n",
    "        update_params = {\n",
    "            self.n_layers -1: (dw, delta)\n",
    "        }\n",
    "        \n",
    "        for i in reversed(range(2,self.n_layers)):\n",
    "            delta = np.dot(delta, self.w[i].T) * self.activations[i].prime(z[i])\n",
    "            \n",
    "        for k,v in update_params.items():\n",
    "            self._update_w_b(k, v[0], v[1])\n",
    "            \n",
    "    def fit(self, x, y_true, loss, epochs, batch_size, learning_rate):\n",
    "        if x.shape[0] != y_true.shape[0]:\n",
    "            raise ValueError('Lengh of x and y arrays dont match')\n",
    "        \n",
    "        self.loss = loss(self.activations[self.n_layers])\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            # Shuffle the data\n",
    "            #stochastic gradient decent for faster processing\n",
    "            #uses sample of points rather than full training set to calculate partial derivatives\n",
    "            seed = np.arange(x.shape[0])\n",
    "            np.random.shuffle(seed)\n",
    "            x_ = x[seed]\n",
    "            y_ = y_true[seed]\n",
    "            \n",
    "            for j in range(x.shape[0] // batch_size):\n",
    "                #\n",
    "                k = j * batch_size\n",
    "                l = (j + 1) * batch_size\n",
    "                z, a = self._feed_forward(x_[k:l])\n",
    "                self._back_prop(z, a, y_[k:l])\n",
    "            \n",
    "            if (i + 1) % 25 == 0:\n",
    "                _, a = self._feed_forward(x)\n",
    "                print(\"Loss:\", self.loss.loss(y_true, a[self.n_layers]))\n",
    "\n",
    "        \n",
    "        \n",
    "class MSE:\n",
    "    def __init__(self, activation_fn):\n",
    "        #param activation_fn: Class object of activation function\n",
    "        self.activation_fn = activation_fn\n",
    "    def activation(self, z):\n",
    "        return self.activation_fn.activation(z)\n",
    "\n",
    "    @staticmethod\n",
    "    def loss(y_true, y_pred):\n",
    "        return np.mean((y_pred - y_true)**2)\n",
    "    @staticmethod\n",
    "    def prime(y_true, y_pred):\n",
    "        #partial derrivative for chain rule\n",
    "        return y_pred - y_true\n",
    "        \n",
    "    def delta(self, y_true, y_pred):\n",
    "        #combining partial activation derivative and derivative of MSE with respect to y_pred\n",
    "         return self.prime(y_true, y_pred) * self.activation_fn.prime(y_pred)\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "-1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-f74b008672eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mRelu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSigmoid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMSE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-7ae1721e325d>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y_true, loss, epochs, batch_size, learning_rate)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                 \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_back_prop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m25\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-7ae1721e325d>\u001b[0m in \u001b[0;36m_back_prop\u001b[1;34m(self, z, a, y_true)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[0mdelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;31m#matrix multiply delta by the given layers transposed inputs and thats the three chains for partial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: -1"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x = inputs\n",
    "y = train_outputs\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "nn = NeuralNetwork((3, 4, 1), (Relu, Sigmoid))\n",
    "nn.fit(X_train,y_train,loss=MSE,epochs=500,batch_size=25,learning_rate=.001)\n",
    "predictions = nn.predict(X_test)\n",
    "y_pred = []\n",
    "for i in predictions:\n",
    "    if i >= 0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "        \n",
    "        \n",
    "        \n",
    "ModelScore(y_test,y_pred,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([[ 0.93781623, -0.35319773, -0.3049401 , -0.61947872],\n",
       "        [ 0.49964333, -1.32879399,  1.00736754, -0.43948301],\n",
       "        [ 0.18419731, -0.14397405,  0.84414841, -1.18942279]]),\n",
       " 2: array([[-2.49693685],\n",
       "        [ 0.20181367],\n",
       "        [ 0.94816911],\n",
       "        [-0.4604523 ]])}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#weights after training\n",
    "#keys represent layers \n",
    "nn.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([1.28077388, 1.39620298, 2.60148914, 2.93652315]),\n",
       " 2: array([2.91015284])}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#bias terms \n",
    "nn.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: array([[1.85799663, 1.82248589, 1.32417048, 3.16742005],\n",
       "        [1.69393094, 0.53674221, 3.76159666, 1.86225538],\n",
       "        [1.06020922, 1.80769417, 1.9174676 , 3.65061624],\n",
       "        ...,\n",
       "        [0.89616461, 2.38835916, 1.78408028, 3.36602933],\n",
       "        [2.07491677, 1.39439592, 1.96490876, 2.53462494],\n",
       "        [2.20393241, 0.90574531, 2.02610706, 2.85342306]]),\n",
       " 3: array([[-1.56425315],\n",
       "        [ 1.49798618],\n",
       "        [ 0.76484367],\n",
       "        [ 1.27662598],\n",
       "        [-1.8720683 ],\n",
       "        [-1.3813331 ],\n",
       "        [-0.84610554],\n",
       "        [ 0.79228574],\n",
       "        [ 1.42074297],\n",
       "        [ 1.450308  ],\n",
       "        [ 0.5142947 ],\n",
       "        [-1.50190129],\n",
       "        [-1.59348185],\n",
       "        [ 1.0598271 ],\n",
       "        [ 0.35572242],\n",
       "        [-0.71533068],\n",
       "        [ 0.8051263 ],\n",
       "        [-1.58046473],\n",
       "        [-1.76697614],\n",
       "        [ 1.03799223],\n",
       "        [-1.25338955],\n",
       "        [ 1.42267009],\n",
       "        [ 0.84986598],\n",
       "        [ 1.51610636],\n",
       "        [-1.67589878],\n",
       "        [-2.15045728],\n",
       "        [-0.49520727],\n",
       "        [-1.30457348],\n",
       "        [-1.52657909],\n",
       "        [ 1.12593771],\n",
       "        [ 1.11485814],\n",
       "        [ 0.44453471],\n",
       "        [ 0.95257348],\n",
       "        [ 1.87915646],\n",
       "        [ 0.93684423],\n",
       "        [ 1.12268865],\n",
       "        [-0.66712844],\n",
       "        [-1.53064042],\n",
       "        [ 1.41288078],\n",
       "        [ 0.9844445 ],\n",
       "        [-1.27967155],\n",
       "        [ 0.93006438],\n",
       "        [-1.72499676],\n",
       "        [ 1.60514103],\n",
       "        [-0.64867024],\n",
       "        [-1.56459105],\n",
       "        [ 1.6395918 ],\n",
       "        [-0.79457055],\n",
       "        [-0.7845868 ],\n",
       "        [ 0.73264197],\n",
       "        [-1.47546412],\n",
       "        [ 0.98694387],\n",
       "        [-1.64001783],\n",
       "        [-1.75823385],\n",
       "        [ 1.64478318],\n",
       "        [-0.46332263],\n",
       "        [-1.54592979],\n",
       "        [-1.01101717],\n",
       "        [-1.63178842],\n",
       "        [-0.68848832],\n",
       "        [ 0.74004869],\n",
       "        [-1.53582383],\n",
       "        [-1.70044578],\n",
       "        [-1.06494379],\n",
       "        [ 1.02877558],\n",
       "        [ 0.72084326],\n",
       "        [-0.97553193],\n",
       "        [ 4.06371704],\n",
       "        [-1.60061249],\n",
       "        [-1.7240015 ],\n",
       "        [-1.50508213],\n",
       "        [-1.1752982 ],\n",
       "        [-1.44649541],\n",
       "        [-2.16161093],\n",
       "        [-1.77581392],\n",
       "        [-0.67743343],\n",
       "        [ 0.81231952],\n",
       "        [-1.55578693],\n",
       "        [ 0.7150137 ],\n",
       "        [-0.40179346],\n",
       "        [-1.81289727],\n",
       "        [-1.92345456],\n",
       "        [-1.70182872],\n",
       "        [ 0.8837652 ],\n",
       "        [-1.94860673],\n",
       "        [-1.33559445],\n",
       "        [ 1.15470734],\n",
       "        [-1.55125689],\n",
       "        [ 0.94377658],\n",
       "        [ 1.09307945],\n",
       "        [-1.52860976],\n",
       "        [-2.22456178],\n",
       "        [-1.51362455],\n",
       "        [ 1.23186232],\n",
       "        [ 1.7364392 ],\n",
       "        [-0.46332263],\n",
       "        [-1.45263876],\n",
       "        [ 0.68688298],\n",
       "        [-0.95432597],\n",
       "        [-1.25262869],\n",
       "        [-1.61536812],\n",
       "        [-2.07937076],\n",
       "        [-1.82521773],\n",
       "        [-1.51814662],\n",
       "        [ 0.38016382],\n",
       "        [ 0.9844445 ],\n",
       "        [-1.54487594],\n",
       "        [-1.46228565],\n",
       "        [ 1.2358248 ],\n",
       "        [-1.18957205],\n",
       "        [-1.38423667],\n",
       "        [-0.44475768],\n",
       "        [ 0.86071194],\n",
       "        [ 0.94294346],\n",
       "        [-1.49834241],\n",
       "        [-1.39649932],\n",
       "        [-1.01098269],\n",
       "        [-1.67877546],\n",
       "        [ 1.6140551 ],\n",
       "        [-1.61748143],\n",
       "        [-1.95956966],\n",
       "        [-2.02338494],\n",
       "        [ 1.81674926],\n",
       "        [-2.12646043],\n",
       "        [-1.90301386],\n",
       "        [-1.20288969],\n",
       "        [ 1.00850744],\n",
       "        [-1.7486793 ],\n",
       "        [-1.91991425],\n",
       "        [ 0.54647412],\n",
       "        [-1.65443556],\n",
       "        [-1.41791763],\n",
       "        [-0.51906164],\n",
       "        [-1.02778507],\n",
       "        [ 0.62046581],\n",
       "        [-0.91230597],\n",
       "        [-1.7331565 ],\n",
       "        [-0.76468628],\n",
       "        [ 1.43390855],\n",
       "        [-1.52860976],\n",
       "        [-1.74923143],\n",
       "        [-1.45572652],\n",
       "        [ 0.60024696],\n",
       "        [-1.66826494],\n",
       "        [-2.02752096],\n",
       "        [-0.85132023],\n",
       "        [-0.5302303 ],\n",
       "        [ 1.53681435],\n",
       "        [-1.75061306],\n",
       "        [-1.87442964],\n",
       "        [-1.89925113],\n",
       "        [ 0.69922188],\n",
       "        [-1.39680914],\n",
       "        [ 0.9364381 ],\n",
       "        [-0.79077512],\n",
       "        [ 0.64223245],\n",
       "        [ 2.32865291],\n",
       "        [-2.03675509],\n",
       "        [ 0.89664429],\n",
       "        [-1.67576798],\n",
       "        [-1.87263898],\n",
       "        [-2.07827417],\n",
       "        [-1.45254569],\n",
       "        [ 1.39833339],\n",
       "        [-1.67132137],\n",
       "        [-1.47553393],\n",
       "        [ 1.00877874],\n",
       "        [-1.62262711],\n",
       "        [-1.61685782],\n",
       "        [ 0.75515107],\n",
       "        [-1.56425315],\n",
       "        [-1.66826494],\n",
       "        [ 2.35289956],\n",
       "        [ 0.74016587],\n",
       "        [-1.72444283],\n",
       "        [ 1.72741606],\n",
       "        [-1.70887825],\n",
       "        [-1.40319009],\n",
       "        [-1.59423154],\n",
       "        [-2.09854155],\n",
       "        [-0.61479739],\n",
       "        [-1.53013797],\n",
       "        [-1.43742245],\n",
       "        [-1.52723645],\n",
       "        [-1.37213134],\n",
       "        [ 1.7700777 ],\n",
       "        [-1.72846896],\n",
       "        [-2.05664359],\n",
       "        [ 1.66423339],\n",
       "        [-1.56081145],\n",
       "        [-1.75364599],\n",
       "        [ 1.50673964],\n",
       "        [-1.43742245],\n",
       "        [-1.7540762 ],\n",
       "        [-1.68420045],\n",
       "        [-1.56628382],\n",
       "        [-1.76208169],\n",
       "        [-0.67878045],\n",
       "        [ 0.78708467],\n",
       "        [ 0.92101227],\n",
       "        [-1.19843875],\n",
       "        [-1.81568794],\n",
       "        [ 0.73203277],\n",
       "        [-1.85608437],\n",
       "        [-1.61790444],\n",
       "        [ 0.59429108],\n",
       "        [ 0.80973903],\n",
       "        [ 1.94260881],\n",
       "        [ 5.14713926],\n",
       "        [ 0.55469113],\n",
       "        [-0.70325343],\n",
       "        [-0.90223992],\n",
       "        [-2.12623216],\n",
       "        [-1.85694505],\n",
       "        [-0.88922865],\n",
       "        [-1.62975776],\n",
       "        [ 2.37334528],\n",
       "        [ 2.61740619],\n",
       "        [-1.75606515],\n",
       "        [ 0.58271629],\n",
       "        [-1.56971263],\n",
       "        [ 1.34666451],\n",
       "        [ 0.29312253],\n",
       "        [-0.83871968],\n",
       "        [ 0.74296708],\n",
       "        [-2.19043871],\n",
       "        [-1.70250453],\n",
       "        [-1.37963437],\n",
       "        [-1.47722349],\n",
       "        [-1.81276244],\n",
       "        [-1.72512358],\n",
       "        [-1.55376192],\n",
       "        [-1.95956966],\n",
       "        [ 0.86071194],\n",
       "        [ 1.91704328],\n",
       "        [ 2.2884552 ],\n",
       "        [-1.81836241],\n",
       "        [ 0.82922619],\n",
       "        [-1.60311752],\n",
       "        [-1.60160775],\n",
       "        [ 3.69034556],\n",
       "        [ 3.1400712 ],\n",
       "        [-1.60799835],\n",
       "        [ 1.30015515],\n",
       "        [ 2.62731547],\n",
       "        [-1.48956638],\n",
       "        [ 1.46222158],\n",
       "        [ 2.03638861],\n",
       "        [ 4.25312673],\n",
       "        [ 1.0584779 ],\n",
       "        [-1.70182872],\n",
       "        [-1.7432431 ],\n",
       "        [ 0.7636935 ],\n",
       "        [ 1.1078335 ],\n",
       "        [-2.01722523],\n",
       "        [ 3.17688576],\n",
       "        [ 2.47560636],\n",
       "        [-1.56425315],\n",
       "        [-1.67715092],\n",
       "        [ 0.73801802],\n",
       "        [ 1.20592507],\n",
       "        [ 2.59272839],\n",
       "        [-2.19102403],\n",
       "        [ 0.60051068],\n",
       "        [ 0.84614575],\n",
       "        [ 1.82476837],\n",
       "        [-1.72096535],\n",
       "        [ 0.14543123],\n",
       "        [-1.24154911],\n",
       "        [-0.77283777],\n",
       "        [ 2.45092856],\n",
       "        [-2.06131638],\n",
       "        [-1.60029983],\n",
       "        [-0.76609731],\n",
       "        [ 4.025099  ],\n",
       "        [-1.61890934],\n",
       "        [-1.54487594],\n",
       "        [-1.81633174],\n",
       "        [ 0.89664429],\n",
       "        [ 0.50179948],\n",
       "        [-0.95485289],\n",
       "        [-2.032417  ],\n",
       "        [-1.55684644],\n",
       "        [-1.39184645],\n",
       "        [-1.46689838],\n",
       "        [-1.67576798],\n",
       "        [ 1.6283035 ],\n",
       "        [ 0.55115508],\n",
       "        [-1.67298762],\n",
       "        [-1.40444297],\n",
       "        [ 0.40203443],\n",
       "        [-1.88831362],\n",
       "        [-1.76167556],\n",
       "        [ 1.31979181],\n",
       "        [ 1.81125604],\n",
       "        [-0.85539677],\n",
       "        [-1.47779417],\n",
       "        [-1.47722349],\n",
       "        [ 0.52137517],\n",
       "        [ 1.54605909],\n",
       "        [ 0.85258927],\n",
       "        [ 0.90388907],\n",
       "        [-1.56749179],\n",
       "        [-1.48169095],\n",
       "        [ 3.17248878],\n",
       "        [ 1.5087735 ],\n",
       "        [-1.80006556],\n",
       "        [ 1.25875612],\n",
       "        [-0.38928923],\n",
       "        [-0.40189224],\n",
       "        [ 0.60051068],\n",
       "        [ 1.05314357],\n",
       "        [-0.07808206],\n",
       "        [-1.53070865],\n",
       "        [-1.70135436],\n",
       "        [ 2.55032196],\n",
       "        [ 0.95675199],\n",
       "        [-1.55538645],\n",
       "        [ 0.64030449],\n",
       "        [-1.76605438],\n",
       "        [-1.53613365],\n",
       "        [ 0.79224722],\n",
       "        [-1.97281017],\n",
       "        [-1.64996809],\n",
       "        [ 0.91909878],\n",
       "        [-1.57261017],\n",
       "        [ 0.9248914 ],\n",
       "        [-1.63701355],\n",
       "        [-2.10357998],\n",
       "        [-0.90855371],\n",
       "        [-1.53104656],\n",
       "        [ 1.92543404],\n",
       "        [-2.05721153],\n",
       "        [ 0.9666501 ],\n",
       "        [ 1.04471109],\n",
       "        [-1.66826494],\n",
       "        [ 1.42326886],\n",
       "        [-1.53172399],\n",
       "        [-1.72684443],\n",
       "        [ 0.82067654],\n",
       "        [-1.25496194],\n",
       "        [ 1.0091223 ],\n",
       "        [ 1.2312225 ],\n",
       "        [-1.7980349 ],\n",
       "        [-1.3987852 ],\n",
       "        [ 0.66363309],\n",
       "        [-1.44289481],\n",
       "        [-1.28870742],\n",
       "        [ 2.88167197],\n",
       "        [ 1.31792149],\n",
       "        [ 0.9900549 ],\n",
       "        [ 0.32690534],\n",
       "        [-1.73355605],\n",
       "        [ 0.59366102],\n",
       "        [-1.47834557],\n",
       "        [-1.62975776],\n",
       "        [ 0.79793309],\n",
       "        [ 0.09198327],\n",
       "        [ 1.2736947 ],\n",
       "        [-1.546852  ],\n",
       "        [ 1.46719061],\n",
       "        [-1.72770307],\n",
       "        [-1.57671321],\n",
       "        [-1.42864641],\n",
       "        [-0.72484619],\n",
       "        [-1.72650652],\n",
       "        [-1.87469696],\n",
       "        [ 0.29437214],\n",
       "        [-1.76922565],\n",
       "        [-1.8473905 ],\n",
       "        [-1.5623239 ],\n",
       "        [-1.99679483],\n",
       "        [-1.96234702],\n",
       "        [-1.81885921],\n",
       "        [ 1.57207126],\n",
       "        [-1.93615144],\n",
       "        [ 0.91416261],\n",
       "        [ 0.93418351],\n",
       "        [ 0.89462405],\n",
       "        [-1.63701355],\n",
       "        [-1.74031505],\n",
       "        [-1.55985392],\n",
       "        [ 1.4279811 ],\n",
       "        [-0.59931464],\n",
       "        [-2.09233736],\n",
       "        [ 0.19839237],\n",
       "        [-0.27645403],\n",
       "        [ 1.87607844],\n",
       "        [-1.77836406],\n",
       "        [-1.7486793 ],\n",
       "        [-1.10291969],\n",
       "        [-1.53957535],\n",
       "        [-1.74631565],\n",
       "        [-1.52641153],\n",
       "        [-1.52657909],\n",
       "        [ 1.40768177],\n",
       "        [ 3.12275615],\n",
       "        [-1.60474205],\n",
       "        [-1.41791763],\n",
       "        [ 0.88538974],\n",
       "        [ 0.52039571],\n",
       "        [ 2.28809801],\n",
       "        [ 0.18579525],\n",
       "        [ 0.8857333 ],\n",
       "        [-1.46417263],\n",
       "        [-0.86295037],\n",
       "        [-1.72887509],\n",
       "        [-1.600472  ],\n",
       "        [ 1.09081981],\n",
       "        [-1.60961565],\n",
       "        [-1.63755105],\n",
       "        [ 0.60925297],\n",
       "        [ 0.8116999 ],\n",
       "        [-1.80053993],\n",
       "        [ 2.05632608],\n",
       "        [-1.55376192],\n",
       "        [ 1.13378996],\n",
       "        [-2.0126698 ],\n",
       "        [ 0.29437214],\n",
       "        [-1.97281017],\n",
       "        [-1.51988832],\n",
       "        [ 1.65074511],\n",
       "        [-1.44120205],\n",
       "        [ 0.67811339],\n",
       "        [ 1.53141744],\n",
       "        [-1.75061306],\n",
       "        [ 2.26629689],\n",
       "        [ 1.53895422],\n",
       "        [ 1.54273948],\n",
       "        [ 1.56369459],\n",
       "        [ 1.51433899],\n",
       "        [-1.50643133],\n",
       "        [-0.44015146],\n",
       "        [-1.87772989],\n",
       "        [ 1.2312225 ],\n",
       "        [-1.62005228],\n",
       "        [-0.73952688],\n",
       "        [ 0.2426924 ],\n",
       "        [-1.38304233],\n",
       "        [-1.56465928],\n",
       "        [ 0.86111807],\n",
       "        [-1.85608437],\n",
       "        [ 0.79550845],\n",
       "        [ 1.60922813],\n",
       "        [ 0.67199011],\n",
       "        [-1.99796233],\n",
       "        [-1.61078668],\n",
       "        [-1.33906277],\n",
       "        [-1.47972852],\n",
       "        [ 0.90443628],\n",
       "        [-1.80121573],\n",
       "        [-2.1256405 ],\n",
       "        [ 0.96399596],\n",
       "        [-1.59884747],\n",
       "        [-1.40319009],\n",
       "        [-1.37244115],\n",
       "        [ 0.64986628],\n",
       "        [ 1.22340169],\n",
       "        [-1.80006556],\n",
       "        [ 1.148137  ],\n",
       "        [ 2.11662322],\n",
       "        [-1.81568794],\n",
       "        [-1.37567733],\n",
       "        [ 2.12746194],\n",
       "        [-1.95700109],\n",
       "        [-0.95943113],\n",
       "        [-1.55125689],\n",
       "        [-1.88709522],\n",
       "        [ 1.42009016],\n",
       "        [-2.08716059],\n",
       "        [-1.62982033],\n",
       "        [-1.63519638],\n",
       "        [-2.22133109],\n",
       "        [-1.26521804],\n",
       "        [ 1.12407882],\n",
       "        [-2.05511219],\n",
       "        [-1.5715298 ],\n",
       "        [-1.77490617],\n",
       "        [-1.75118432],\n",
       "        [-1.30993837],\n",
       "        [ 1.41027826],\n",
       "        [ 2.76216641],\n",
       "        [ 0.82336058],\n",
       "        [-1.8720683 ],\n",
       "        [ 1.74140114],\n",
       "        [-1.74423269],\n",
       "        [ 0.89764919],\n",
       "        [ 1.81257872],\n",
       "        [-1.61016705],\n",
       "        [-1.57060759],\n",
       "        [-1.29526581],\n",
       "        [-1.37694713],\n",
       "        [-1.52975993],\n",
       "        [-1.39580423],\n",
       "        [-1.7529609 ],\n",
       "        [-2.06354919],\n",
       "        [ 2.02594633],\n",
       "        [-1.65247312],\n",
       "        [-1.90981791],\n",
       "        [-2.11526579],\n",
       "        [-1.43332737],\n",
       "        [ 1.50886662],\n",
       "        [ 0.79793309],\n",
       "        [-1.80006556],\n",
       "        [-1.4776922 ],\n",
       "        [ 0.91066877],\n",
       "        [-1.50508213],\n",
       "        [ 1.81125604],\n",
       "        [ 1.68161123],\n",
       "        [ 1.57207126],\n",
       "        [-0.92647732],\n",
       "        [-1.47972852],\n",
       "        [-1.66854598],\n",
       "        [ 0.83278507],\n",
       "        [ 1.20716433],\n",
       "        [-1.52035226],\n",
       "        [ 0.94317781],\n",
       "        [-0.53735603],\n",
       "        [ 0.73983519],\n",
       "        [-1.49552034],\n",
       "        [-0.51619442],\n",
       "        [-0.2238597 ],\n",
       "        [-2.00885969],\n",
       "        [-1.77918642],\n",
       "        [-1.90574926],\n",
       "        [-1.50393196],\n",
       "        [-0.73477843],\n",
       "        [-1.54487594],\n",
       "        [-2.04890799],\n",
       "        [ 0.92417791],\n",
       "        [-1.0593751 ],\n",
       "        [-2.17527406],\n",
       "        [-1.69294274],\n",
       "        [-1.45701315],\n",
       "        [-1.61295139],\n",
       "        [ 0.99340348],\n",
       "        [ 0.97848257],\n",
       "        [ 2.49619213],\n",
       "        [-0.55893003],\n",
       "        [-1.48281304],\n",
       "        [-0.72270365],\n",
       "        [-1.63458105],\n",
       "        [-1.08059757],\n",
       "        [-0.83987305],\n",
       "        [-1.44277041],\n",
       "        [-1.45667525],\n",
       "        [ 4.06843142],\n",
       "        [-0.97814848],\n",
       "        [ 1.39696972],\n",
       "        [-1.63869269],\n",
       "        [-1.84367599],\n",
       "        [-2.01321423],\n",
       "        [-2.05511219],\n",
       "        [-0.35907112],\n",
       "        [-2.04942171],\n",
       "        [ 4.04790219],\n",
       "        [-1.5757942 ],\n",
       "        [ 1.06833504],\n",
       "        [-1.63029873],\n",
       "        [-1.65314893],\n",
       "        [-1.67917593],\n",
       "        [ 0.38653314],\n",
       "        [-1.7364091 ],\n",
       "        [ 3.19678955],\n",
       "        [ 1.48966685],\n",
       "        [-1.34179865],\n",
       "        [-1.70071707],\n",
       "        [-2.02161161],\n",
       "        [-1.48372162],\n",
       "        [ 3.27554144],\n",
       "        [ 0.78199758],\n",
       "        [-1.82718016],\n",
       "        [ 1.66575118],\n",
       "        [-1.44404498],\n",
       "        [-1.76697614],\n",
       "        [-2.00920322],\n",
       "        [-0.94279404],\n",
       "        [-1.49195103],\n",
       "        [ 0.87854008],\n",
       "        [-1.33368673],\n",
       "        [ 0.78952147],\n",
       "        [ 3.52777889],\n",
       "        [-1.10536692],\n",
       "        [-1.49552034],\n",
       "        [-1.49552034],\n",
       "        [-1.58088774],\n",
       "        [ 0.70775576],\n",
       "        [ 2.51633656],\n",
       "        [-0.74657715],\n",
       "        [ 4.13727262],\n",
       "        [-1.46983763],\n",
       "        [-1.77538776],\n",
       "        [-1.15919023],\n",
       "        [-1.20499713],\n",
       "        [ 0.74857748],\n",
       "        [-0.74537164],\n",
       "        [-1.77823069],\n",
       "        [ 1.55265354],\n",
       "        [-1.08452653],\n",
       "        [-1.79915698],\n",
       "        [-1.57843972],\n",
       "        [ 1.22209571],\n",
       "        [-0.88188141],\n",
       "        [-1.70345326],\n",
       "        [-1.39649932],\n",
       "        [-1.8473905 ],\n",
       "        [ 1.86857541],\n",
       "        [-2.03516203],\n",
       "        [-1.51523545],\n",
       "        [ 2.33876036],\n",
       "        [-1.40765755],\n",
       "        [ 1.42111485],\n",
       "        [ 0.65095063],\n",
       "        [-1.79295823],\n",
       "        [-1.57705677],\n",
       "        [-2.08321738],\n",
       "        [ 0.25094277],\n",
       "        [ 0.47949003],\n",
       "        [-1.45741929],\n",
       "        [ 1.3569937 ],\n",
       "        [ 3.04812524],\n",
       "        [ 1.07435158],\n",
       "        [ 1.78418315],\n",
       "        [-1.36741663],\n",
       "        [-1.64153562],\n",
       "        [-1.63828655],\n",
       "        [ 0.95529358],\n",
       "        [-0.86339748],\n",
       "        [-0.8295504 ],\n",
       "        [-0.8725724 ],\n",
       "        [-1.11158652],\n",
       "        [-1.62779532],\n",
       "        [-1.89036515],\n",
       "        [ 0.55970626],\n",
       "        [ 0.65377349],\n",
       "        [-1.76201346],\n",
       "        [ 0.92971285],\n",
       "        [-1.76697614],\n",
       "        [ 0.93915023],\n",
       "        [ 0.53886295],\n",
       "        [-0.86590246],\n",
       "        [-1.69210962],\n",
       "        [-1.77782456],\n",
       "        [-2.10155436],\n",
       "        [ 0.95982927],\n",
       "        [-1.89036515],\n",
       "        [ 1.32598158],\n",
       "        [-1.65260796],\n",
       "        [-1.70922978],\n",
       "        [-1.83226725],\n",
       "        [ 1.63772799],\n",
       "        [-1.7610182 ],\n",
       "        [ 0.83887707],\n",
       "        [-1.30298673],\n",
       "        [-2.07577963],\n",
       "        [-0.9326536 ],\n",
       "        [ 1.67592999],\n",
       "        [-1.66469563],\n",
       "        [-2.07687656],\n",
       "        [ 0.81408209],\n",
       "        [-0.54373944],\n",
       "        [-0.56265272],\n",
       "        [ 1.38715859],\n",
       "        [ 1.14236844],\n",
       "        [-0.85500289],\n",
       "        [-1.57911553],\n",
       "        [-1.44848436],\n",
       "        [ 1.6662216 ],\n",
       "        [-1.51662883],\n",
       "        [-1.01101717],\n",
       "        [-1.50393196],\n",
       "        [-1.36338905],\n",
       "        [ 1.04099332],\n",
       "        [-1.88592498],\n",
       "        [-1.41791763],\n",
       "        [-2.05110118],\n",
       "        [-1.87457333],\n",
       "        [-1.29400286],\n",
       "        [-0.72975883],\n",
       "        [-2.2458566 ],\n",
       "        [ 1.30329504],\n",
       "        [ 1.52294325],\n",
       "        [ 0.61427749],\n",
       "        [ 0.98541566],\n",
       "        [ 2.70864594],\n",
       "        [-1.78783823],\n",
       "        [ 0.9983124 ],\n",
       "        [-1.92171605],\n",
       "        [-1.47053272],\n",
       "        [ 0.56591045],\n",
       "        [-1.52019814],\n",
       "        [ 0.45244388],\n",
       "        [ 0.83655425],\n",
       "        [-1.08381132],\n",
       "        [-1.05696728],\n",
       "        [-1.65247312],\n",
       "        [ 1.01927551],\n",
       "        [-1.87226094],\n",
       "        [-2.05776974],\n",
       "        [ 0.97663165],\n",
       "        [ 1.02492774],\n",
       "        [-1.47272794],\n",
       "        [-1.47972852],\n",
       "        [ 1.4774267 ],\n",
       "        [ 1.0831557 ],\n",
       "        [-1.82521773],\n",
       "        [ 0.90565787],\n",
       "        [-1.65952265],\n",
       "        [-1.64153562],\n",
       "        [ 0.78843313],\n",
       "        [-1.59423154],\n",
       "        [ 1.2962038 ],\n",
       "        [-1.29338323],\n",
       "        [-1.80290849]])}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inputs (f(z)) at each neuron\n",
    "#first row = frist row of train X summed with weights and bias 4 differnt times (for four relu neurons)\n",
    "#z = x*w +b\n",
    "z, a = nn._feed_forward(x)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([[ 1.        , -0.53037664, -0.51897787],\n",
       "        [ 0.        ,  0.57183099,  0.69189675],\n",
       "        [ 0.        , -0.25482473, -0.50621356],\n",
       "        ...,\n",
       "        [ 0.        , -0.73704057, -0.08877362],\n",
       "        [ 1.        , -0.25482473, -0.08877362],\n",
       "        [ 1.        ,  0.15850313, -0.50952283]]),\n",
       " 2: array([[1.85799663, 1.82248589, 1.32417048, 3.16742005],\n",
       "        [1.69393094, 0.53674221, 3.76159666, 1.86225538],\n",
       "        [1.06020922, 1.80769417, 1.9174676 , 3.65061624],\n",
       "        ...,\n",
       "        [0.89616461, 2.38835916, 1.78408028, 3.36602933],\n",
       "        [2.07491677, 1.39439592, 1.96490876, 2.53462494],\n",
       "        [2.20393241, 0.90574531, 2.02610706, 2.85342306]]),\n",
       " 3: array([[0.17303719],\n",
       "        [0.81727393],\n",
       "        [0.68240442],\n",
       "        [0.7818749 ],\n",
       "        [0.13330258],\n",
       "        [0.20079498],\n",
       "        [0.30025045],\n",
       "        [0.68832191],\n",
       "        [0.80545486],\n",
       "        [0.81004583],\n",
       "        [0.62581271],\n",
       "        [0.18214212],\n",
       "        [0.16889459],\n",
       "        [0.7426575 ],\n",
       "        [0.58800456],\n",
       "        [0.32842203],\n",
       "        [0.69106998],\n",
       "        [0.17072967],\n",
       "        [0.14591878],\n",
       "        [0.73846242],\n",
       "        [0.22211394],\n",
       "        [0.80575666],\n",
       "        [0.70053903],\n",
       "        [0.81996441],\n",
       "        [0.1576393 ],\n",
       "        [0.1042885 ],\n",
       "        [0.37866764],\n",
       "        [0.21339631],\n",
       "        [0.17849476],\n",
       "        [0.75508844],\n",
       "        [0.75303371],\n",
       "        [0.60933903],\n",
       "        [0.72163243],\n",
       "        [0.86751421],\n",
       "        [0.71846177],\n",
       "        [0.75448709],\n",
       "        [0.33914013],\n",
       "        [0.1779    ],\n",
       "        [0.80421992],\n",
       "        [0.72798921],\n",
       "        [0.21760614],\n",
       "        [0.71708835],\n",
       "        [0.15122867],\n",
       "        [0.83273569],\n",
       "        [0.34328926],\n",
       "        [0.17298885],\n",
       "        [0.83747939],\n",
       "        [0.31118813],\n",
       "        [0.31333217],\n",
       "        [0.67538477],\n",
       "        [0.18611351],\n",
       "        [0.72848386],\n",
       "        [0.16246264],\n",
       "        [0.14701168],\n",
       "        [0.83818474],\n",
       "        [0.3861979 ],\n",
       "        [0.17567491],\n",
       "        [0.26678084],\n",
       "        [0.16358551],\n",
       "        [0.33436944],\n",
       "        [0.6770065 ],\n",
       "        [0.17714319],\n",
       "        [0.15440705],\n",
       "        [0.25636582],\n",
       "        [0.73667845],\n",
       "        [0.67279268],\n",
       "        [0.27377925],\n",
       "        [0.98310531],\n",
       "        [0.16789603],\n",
       "        [0.15135646],\n",
       "        [0.18166877],\n",
       "        [0.23589864],\n",
       "        [0.19054151],\n",
       "        [0.1032512 ],\n",
       "        [0.1448208 ],\n",
       "        [0.33683437],\n",
       "        [0.69260356],\n",
       "        [0.17425203],\n",
       "        [0.67150806],\n",
       "        [0.40088152],\n",
       "        [0.14028833],\n",
       "        [0.12747683],\n",
       "        [0.15422657],\n",
       "        [0.70760186],\n",
       "        [0.12470536],\n",
       "        [0.20823548],\n",
       "        [0.76036968],\n",
       "        [0.17490481],\n",
       "        [0.71986188],\n",
       "        [0.74896116],\n",
       "        [0.17819719],\n",
       "        [0.09756641],\n",
       "        [0.18040226],\n",
       "        [0.77414436],\n",
       "        [0.85023421],\n",
       "        [0.3861979 ],\n",
       "        [0.18959579],\n",
       "        [0.66527317],\n",
       "        [0.27801567],\n",
       "        [0.22224543],\n",
       "        [0.16584465],\n",
       "        [0.1111181 ],\n",
       "        [0.13880896],\n",
       "        [0.1797346 ],\n",
       "        [0.59391261],\n",
       "        [0.72798921],\n",
       "        [0.17582757],\n",
       "        [0.18811799],\n",
       "        [0.77483642],\n",
       "        [0.23333548],\n",
       "        [0.20032943],\n",
       "        [0.39060789],\n",
       "        [0.70280938],\n",
       "        [0.71969384],\n",
       "        [0.18267288],\n",
       "        [0.1983722 ],\n",
       "        [0.26678758],\n",
       "        [0.15725769],\n",
       "        [0.83397362],\n",
       "        [0.1655525 ],\n",
       "        [0.12351363],\n",
       "        [0.11676943],\n",
       "        [0.86017561],\n",
       "        [0.10655148],\n",
       "        [0.12976774],\n",
       "        [0.23096156],\n",
       "        [0.73272795],\n",
       "        [0.14821385],\n",
       "        [0.12787113],\n",
       "        [0.63331717],\n",
       "        [0.16051037],\n",
       "        [0.19498824],\n",
       "        [0.37307168],\n",
       "        [0.26351374],\n",
       "        [0.65032448],\n",
       "        [0.2865282 ],\n",
       "        [0.15018427],\n",
       "        [0.31762969],\n",
       "        [0.80750958],\n",
       "        [0.17819719],\n",
       "        [0.14814416],\n",
       "        [0.18912181],\n",
       "        [0.6457128 ],\n",
       "        [0.15865564],\n",
       "        [0.11634354],\n",
       "        [0.29915598],\n",
       "        [0.37046318],\n",
       "        [0.82300115],\n",
       "        [0.14796989],\n",
       "        [0.13303001],\n",
       "        [0.13019326],\n",
       "        [0.66801523],\n",
       "        [0.19832294],\n",
       "        [0.71837961],\n",
       "        [0.31200226],\n",
       "        [0.65525793],\n",
       "        [0.91122242],\n",
       "        [0.11539756],\n",
       "        [0.71025941],\n",
       "        [0.15765667],\n",
       "        [0.13323667],\n",
       "        [0.11122646],\n",
       "        [0.18961009],\n",
       "        [0.80191929],\n",
       "        [0.15824809],\n",
       "        [0.18610294],\n",
       "        [0.73278108],\n",
       "        [0.16484288],\n",
       "        [0.16563867],\n",
       "        [0.68030006],\n",
       "        [0.17303719],\n",
       "        [0.15865564],\n",
       "        [0.91316442],\n",
       "        [0.67703213],\n",
       "        [0.15129978],\n",
       "        [0.84908161],\n",
       "        [0.15330927],\n",
       "        [0.19731038],\n",
       "        [0.16878938],\n",
       "        [0.10923866],\n",
       "        [0.35096563],\n",
       "        [0.1779735 ],\n",
       "        [0.19194481],\n",
       "        [0.17839839],\n",
       "        [0.20227572],\n",
       "        [0.85446733],\n",
       "        [0.15078352],\n",
       "        [0.1133828 ],\n",
       "        [0.84080547],\n",
       "        [0.17353024],\n",
       "        [0.14758792],\n",
       "        [0.81857752],\n",
       "        [0.19194481],\n",
       "        [0.14753381],\n",
       "        [0.15654006],\n",
       "        [0.17274681],\n",
       "        [0.14652981],\n",
       "        [0.33653355],\n",
       "        [0.68720501],\n",
       "        [0.71524832],\n",
       "        [0.23175307],\n",
       "        [0.13995209],\n",
       "        [0.67525119],\n",
       "        [0.1351601 ],\n",
       "        [0.16549408],\n",
       "        [0.64434911],\n",
       "        [0.69205389],\n",
       "        [0.87463847],\n",
       "        [0.99421761],\n",
       "        [0.63522328],\n",
       "        [0.3310913 ],\n",
       "        [0.28859041],\n",
       "        [0.10657322],\n",
       "        [0.13505953],\n",
       "        [0.29126903],\n",
       "        [0.16386355],\n",
       "        [0.91477203],\n",
       "        [0.93197345],\n",
       "        [0.14728384],\n",
       "        [0.64169218],\n",
       "        [0.17225736],\n",
       "        [0.79358378],\n",
       "        [0.57276041],\n",
       "        [0.3018045 ],\n",
       "        [0.67764433],\n",
       "        [0.10061239],\n",
       "        [0.15413844],\n",
       "        [0.20106773],\n",
       "        [0.18584716],\n",
       "        [0.14030459],\n",
       "        [0.15121239],\n",
       "        [0.17454359],\n",
       "        [0.12351363],\n",
       "        [0.70280938],\n",
       "        [0.87180836],\n",
       "        [0.90791638],\n",
       "        [0.13963049],\n",
       "        [0.69619129],\n",
       "        [0.16754635],\n",
       "        [0.16775703],\n",
       "        [0.97564462],\n",
       "        [0.95851571],\n",
       "        [0.1668667 ],\n",
       "        [0.78586109],\n",
       "        [0.932599  ],\n",
       "        [0.18398682],\n",
       "        [0.81187222],\n",
       "        [0.88456502],\n",
       "        [0.98597966],\n",
       "        [0.74239956],\n",
       "        [0.15422657],\n",
       "        [0.14890147],\n",
       "        [0.68215509],\n",
       "        [0.75172499],\n",
       "        [0.11740621],\n",
       "        [0.95995512],\n",
       "        [0.92241394],\n",
       "        [0.17303719],\n",
       "        [0.1574731 ],\n",
       "        [0.6765623 ],\n",
       "        [0.76957714],\n",
       "        [0.93039212],\n",
       "        [0.10055944],\n",
       "        [0.64577313],\n",
       "        [0.699758  ],\n",
       "        [0.86113731],\n",
       "        [0.15174686],\n",
       "        [0.53629386],\n",
       "        [0.22416646],\n",
       "        [0.31586556],\n",
       "        [0.92062933],\n",
       "        [0.11291391],\n",
       "        [0.16793971],\n",
       "        [0.31732394],\n",
       "        [0.98245178],\n",
       "        [0.16535534],\n",
       "        [0.17582757],\n",
       "        [0.13987462],\n",
       "        [0.71025941],\n",
       "        [0.62288212],\n",
       "        [0.27790991],\n",
       "        [0.11584114],\n",
       "        [0.17409963],\n",
       "        [0.19911315],\n",
       "        [0.1874145 ],\n",
       "        [0.15765667],\n",
       "        [0.8359371 ],\n",
       "        [0.63440354],\n",
       "        [0.15802626],\n",
       "        [0.19711203],\n",
       "        [0.59917635],\n",
       "        [0.13143687],\n",
       "        [0.14658061],\n",
       "        [0.78914707],\n",
       "        [0.85951361],\n",
       "        [0.29830199],\n",
       "        [0.18576083],\n",
       "        [0.18584716],\n",
       "        [0.62746927],\n",
       "        [0.82434381],\n",
       "        [0.70111002],\n",
       "        [0.71174805],\n",
       "        [0.17257425],\n",
       "        [0.18517215],\n",
       "        [0.95978575],\n",
       "        [0.81887937],\n",
       "        [0.14184308],\n",
       "        [0.77881191],\n",
       "        [0.40388842],\n",
       "        [0.40085779],\n",
       "        [0.64577313],\n",
       "        [0.74137809],\n",
       "        [0.4804894 ],\n",
       "        [0.17789003],\n",
       "        [0.15428846],\n",
       "        [0.92759514],\n",
       "        [0.72247103],\n",
       "        [0.17430966],\n",
       "        [0.65482229],\n",
       "        [0.14603369],\n",
       "        [0.17709803],\n",
       "        [0.68831365],\n",
       "        [0.12208737],\n",
       "        [0.16111326],\n",
       "        [0.71485844],\n",
       "        [0.17184461],\n",
       "        [0.71603771],\n",
       "        [0.16287184],\n",
       "        [0.10874935],\n",
       "        [0.28729588],\n",
       "        [0.17784061],\n",
       "        [0.87274318],\n",
       "        [0.11332572],\n",
       "        [0.72445129],\n",
       "        [0.73975799],\n",
       "        [0.15865564],\n",
       "        [0.80585036],\n",
       "        [0.17774159],\n",
       "        [0.15099166],\n",
       "        [0.69437993],\n",
       "        [0.22184239],\n",
       "        [0.73284835],\n",
       "        [0.77403247],\n",
       "        [0.14209044],\n",
       "        [0.19800895],\n",
       "        [0.66007604],\n",
       "        [0.19109747],\n",
       "        [0.21607167],\n",
       "        [0.94693294],\n",
       "        [0.78883569],\n",
       "        [0.72909877],\n",
       "        [0.58100621],\n",
       "        [0.15013329],\n",
       "        [0.64420471],\n",
       "        [0.18567744],\n",
       "        [0.16386355],\n",
       "        [0.68953217],\n",
       "        [0.52297962],\n",
       "        [0.78137456],\n",
       "        [0.1755414 ],\n",
       "        [0.81263   ],\n",
       "        [0.15088162],\n",
       "        [0.17126147],\n",
       "        [0.19330968],\n",
       "        [0.32632671],\n",
       "        [0.15103498],\n",
       "        [0.13299918],\n",
       "        [0.57306617],\n",
       "        [0.14563865],\n",
       "        [0.13617957],\n",
       "        [0.17331344],\n",
       "        [0.11953985],\n",
       "        [0.12321327],\n",
       "        [0.13957082],\n",
       "        [0.82807868],\n",
       "        [0.12607127],\n",
       "        [0.71385121],\n",
       "        [0.71792326],\n",
       "        [0.70984349],\n",
       "        [0.16287184],\n",
       "        [0.14927292],\n",
       "        [0.17366761],\n",
       "        [0.80658655],\n",
       "        [0.35450051],\n",
       "        [0.10984382],\n",
       "        [0.54943605],\n",
       "        [0.43132333],\n",
       "        [0.86716004],\n",
       "        [0.14450526],\n",
       "        [0.14821385],\n",
       "        [0.24919323],\n",
       "        [0.17659701],\n",
       "        [0.1485125 ],\n",
       "        [0.17851933],\n",
       "        [0.17849476],\n",
       "        [0.80340004],\n",
       "        [0.95782172],\n",
       "        [0.16731989],\n",
       "        [0.19498824],\n",
       "        [0.70793786],\n",
       "        [0.62724029],\n",
       "        [0.90788651],\n",
       "        [0.54631565],\n",
       "        [0.70800889],\n",
       "        [0.18782996],\n",
       "        [0.2967233 ],\n",
       "        [0.15073152],\n",
       "        [0.16791566],\n",
       "        [0.74853607],\n",
       "        [0.16664198],\n",
       "        [0.16279857],\n",
       "        [0.64777038],\n",
       "        [0.69247162],\n",
       "        [0.14178535],\n",
       "        [0.88658527],\n",
       "        [0.17454359],\n",
       "        [0.75653764],\n",
       "        [0.11787908],\n",
       "        [0.57306617],\n",
       "        [0.12208737],\n",
       "        [0.17947796],\n",
       "        [0.83899173],\n",
       "        [0.19135927],\n",
       "        [0.6633175 ],\n",
       "        [0.82221361],\n",
       "        [0.14796989],\n",
       "        [0.90604703],\n",
       "        [0.82331265],\n",
       "        [0.82386261],\n",
       "        [0.82688286],\n",
       "        [0.81970336],\n",
       "        [0.18146827],\n",
       "        [0.39170488],\n",
       "        [0.13264984],\n",
       "        [0.77403247],\n",
       "        [0.16519766],\n",
       "        [0.32310761],\n",
       "        [0.56037704],\n",
       "        [0.20052083],\n",
       "        [0.17297909],\n",
       "        [0.7028942 ],\n",
       "        [0.1351601 ],\n",
       "        [0.68901288],\n",
       "        [0.8333042 ],\n",
       "        [0.66194863],\n",
       "        [0.11941703],\n",
       "        [0.16647942],\n",
       "        [0.20766423],\n",
       "        [0.18546843],\n",
       "        [0.71186031],\n",
       "        [0.14170314],\n",
       "        [0.10662956],\n",
       "        [0.72392115],\n",
       "        [0.16814276],\n",
       "        [0.19731038],\n",
       "        [0.20222573],\n",
       "        [0.65698033],\n",
       "        [0.77266163],\n",
       "        [0.14184308],\n",
       "        [0.75917047],\n",
       "        [0.8925084 ],\n",
       "        [0.13995209],\n",
       "        [0.20170414],\n",
       "        [0.89354382],\n",
       "        [0.12379196],\n",
       "        [0.27699211],\n",
       "        [0.17490481],\n",
       "        [0.13157603],\n",
       "        [0.80535255],\n",
       "        [0.11035102],\n",
       "        [0.16385498],\n",
       "        [0.16311975],\n",
       "        [0.09785124],\n",
       "        [0.22007694],\n",
       "        [0.75474451],\n",
       "        [0.11353684],\n",
       "        [0.17199842],\n",
       "        [0.14493326],\n",
       "        [0.14789788],\n",
       "        [0.21249716],\n",
       "        [0.80380983],\n",
       "        [0.9405968 ],\n",
       "        [0.69494923],\n",
       "        [0.13330258],\n",
       "        [0.85086495],\n",
       "        [0.1487761 ],\n",
       "        [0.71046617],\n",
       "        [0.85967325],\n",
       "        [0.16656542],\n",
       "        [0.17212979],\n",
       "        [0.21496285],\n",
       "        [0.20149975],\n",
       "        [0.17802881],\n",
       "        [0.19848276],\n",
       "        [0.14767413],\n",
       "        [0.11269045],\n",
       "        [0.88349447],\n",
       "        [0.16077498],\n",
       "        [0.12900131],\n",
       "        [0.1076219 ],\n",
       "        [0.19258077],\n",
       "        [0.81889318],\n",
       "        [0.68953217],\n",
       "        [0.14184308],\n",
       "        [0.18577625],\n",
       "        [0.71313699],\n",
       "        [0.18166877],\n",
       "        [0.85951361],\n",
       "        [0.84311777],\n",
       "        [0.82807868],\n",
       "        [0.28363994],\n",
       "        [0.18546843],\n",
       "        [0.15861813],\n",
       "        [0.6969435 ],\n",
       "        [0.76979683],\n",
       "        [0.17940965],\n",
       "        [0.71974111],\n",
       "        [0.36880285],\n",
       "        [0.67695982],\n",
       "        [0.1830946 ],\n",
       "        [0.37374254],\n",
       "        [0.44426762],\n",
       "        [0.11827584],\n",
       "        [0.14440362],\n",
       "        [0.12945915],\n",
       "        [0.18183982],\n",
       "        [0.32414701],\n",
       "        [0.17582757],\n",
       "        [0.11416277],\n",
       "        [0.71589262],\n",
       "        [0.25742889],\n",
       "        [0.10199297],\n",
       "        [0.15538923],\n",
       "        [0.18892458],\n",
       "        [0.16617925],\n",
       "        [0.72975965],\n",
       "        [0.72680702],\n",
       "        [0.92387444],\n",
       "        [0.36379507],\n",
       "        [0.1850029 ],\n",
       "        [0.3267979 ],\n",
       "        [0.16320377],\n",
       "        [0.25339295],\n",
       "        [0.30156152],\n",
       "        [0.1911167 ],\n",
       "        [0.18897636],\n",
       "        [0.98318344],\n",
       "        [0.27325932],\n",
       "        [0.80170259],\n",
       "        [0.16264303],\n",
       "        [0.13661712],\n",
       "        [0.11782248],\n",
       "        [0.11353684],\n",
       "        [0.41118444],\n",
       "        [0.11411083],\n",
       "        [0.98284062],\n",
       "        [0.17139195],\n",
       "        [0.74428016],\n",
       "        [0.16378944],\n",
       "        [0.16068382],\n",
       "        [0.15720462],\n",
       "        [0.59544785],\n",
       "        [0.14976962],\n",
       "        [0.96071328],\n",
       "        [0.81602826],\n",
       "        [0.20721443],\n",
       "        [0.15437163],\n",
       "        [0.11695245],\n",
       "        [0.18486595],\n",
       "        [0.96358014],\n",
       "        [0.68611048],\n",
       "        [0.13857454],\n",
       "        [0.84100852],\n",
       "        [0.19091974],\n",
       "        [0.14591878],\n",
       "        [0.11824002],\n",
       "        [0.2803363 ],\n",
       "        [0.18362907],\n",
       "        [0.7065196 ],\n",
       "        [0.20855019],\n",
       "        [0.68772857],\n",
       "        [0.97146791],\n",
       "        [0.24873565],\n",
       "        [0.1830946 ],\n",
       "        [0.1830946 ],\n",
       "        [0.17066979],\n",
       "        [0.66990507],\n",
       "        [0.92527917],\n",
       "        [0.32156758],\n",
       "        [0.98428458],\n",
       "        [0.18696729],\n",
       "        [0.14487359],\n",
       "        [0.23881446],\n",
       "        [0.23058745],\n",
       "        [0.67886866],\n",
       "        [0.32183063],\n",
       "        [0.14452175],\n",
       "        [0.82529665],\n",
       "        [0.25265037],\n",
       "        [0.14195372],\n",
       "        [0.17101657],\n",
       "        [0.77243215],\n",
       "        [0.29278806],\n",
       "        [0.15401479],\n",
       "        [0.1983722 ],\n",
       "        [0.13617957],\n",
       "        [0.86629335],\n",
       "        [0.11556028],\n",
       "        [0.18016419],\n",
       "        [0.91203669],\n",
       "        [0.19660378],\n",
       "        [0.80551313],\n",
       "        [0.65722465],\n",
       "        [0.14271042],\n",
       "        [0.17121272],\n",
       "        [0.11073874],\n",
       "        [0.56240854],\n",
       "        [0.61762745],\n",
       "        [0.18886236],\n",
       "        [0.79527066],\n",
       "        [0.95470152],\n",
       "        [0.74542358],\n",
       "        [0.85621263],\n",
       "        [0.20303755],\n",
       "        [0.16225622],\n",
       "        [0.16269835],\n",
       "        [0.72217851],\n",
       "        [0.29663   ],\n",
       "        [0.30374014],\n",
       "        [0.29471932],\n",
       "        [0.24757523],\n",
       "        [0.1641326 ],\n",
       "        [0.13120284],\n",
       "        [0.63638457],\n",
       "        [0.65786031],\n",
       "        [0.14653835],\n",
       "        [0.71701703],\n",
       "        [0.14591878],\n",
       "        [0.71892798],\n",
       "        [0.63154787],\n",
       "        [0.29610763],\n",
       "        [0.15549861],\n",
       "        [0.14457196],\n",
       "        [0.10894584],\n",
       "        [0.72308762],\n",
       "        [0.13120284],\n",
       "        [0.79017516],\n",
       "        [0.16075679],\n",
       "        [0.15326364],\n",
       "        [0.1379684 ],\n",
       "        [0.83722555],\n",
       "        [0.14666286],\n",
       "        [0.69822866],\n",
       "        [0.21366278],\n",
       "        [0.1114733 ],\n",
       "        [0.28238667],\n",
       "        [0.84236484],\n",
       "        [0.15913267],\n",
       "        [0.1113647 ],\n",
       "        [0.69297869],\n",
       "        [0.36731812],\n",
       "        [0.36293389],\n",
       "        [0.80013824],\n",
       "        [0.75811422],\n",
       "        [0.29838444],\n",
       "        [0.17092078],\n",
       "        [0.19023493],\n",
       "        [0.84107141],\n",
       "        [0.17995848],\n",
       "        [0.26678084],\n",
       "        [0.18183982],\n",
       "        [0.20369005],\n",
       "        [0.73904162],\n",
       "        [0.1317098 ],\n",
       "        [0.19498824],\n",
       "        [0.11394116],\n",
       "        [0.13301344],\n",
       "        [0.21517606],\n",
       "        [0.32524765],\n",
       "        [0.09570747],\n",
       "        [0.78638901],\n",
       "        [0.82097148],\n",
       "        [0.64891594],\n",
       "        [0.72818148],\n",
       "        [0.9375349 ],\n",
       "        [0.14333797],\n",
       "        [0.73072665],\n",
       "        [0.12767033],\n",
       "        [0.18686166],\n",
       "        [0.637819  ],\n",
       "        [0.17943234],\n",
       "        [0.61122013],\n",
       "        [0.697739  ],\n",
       "        [0.25278544],\n",
       "        [0.25788944],\n",
       "        [0.16077498],\n",
       "        [0.73483145],\n",
       "        [0.13328033],\n",
       "        [0.11326964],\n",
       "        [0.72643935],\n",
       "        [0.73593135],\n",
       "        [0.18652833],\n",
       "        [0.18546843],\n",
       "        [0.81418358],\n",
       "        [0.74709071],\n",
       "        [0.13880896],\n",
       "        [0.71211081],\n",
       "        [0.15982609],\n",
       "        [0.16225622],\n",
       "        [0.68749479],\n",
       "        [0.16878938],\n",
       "        [0.7851954 ],\n",
       "        [0.21528071],\n",
       "        [0.14149738]])}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#activations of z f(z)\n",
    "#outpluts from layers\n",
    "#1 is the input layer so the given data\n",
    "#2 is outputs from weights*x + B passed through relu function (4 nodes = four columns, each row= row of data)\n",
    "#3 is output of z func from second to 3rd layer, then passed through sigmoid funcion\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
